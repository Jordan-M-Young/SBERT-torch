# SBERT-torch
Pytorch Implementation of Sentence-BERT

# Data

The paper uses the [SNLI](https://nlp.stanford.edu/projects/snli/) and [MNLI](https://cims.nyu.edu/~sbowman/multinli/) datasets to train SBERT models, we make use of these datasets as well.

Pytorch Implementation of Sentence-BERT architecture from the 2019 Paper [Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks](https://arxiv.org/pdf/1908.10084).

